{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd715de-24af-4a2c-950c-5fddff90d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import warnings\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7922b97-653a-4fc3-b3cb-76da5a6fd819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rao.ans/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rao.ans/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rao.ans/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/rao.ans/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226a6bdb-620b-403d-8a40-604da446833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2047dfae-d5ba-4e22-8879-ea930e865a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/user_info/popular_tweets.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a807ff-0b63-4aa0-9c04-d0ea909f8a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>bear_bull_tag</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>message_id</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$AB | AllianceBernstein Q4 21 Earnings: \\nAdj ...</td>\n",
       "      <td>2022-02-11T11:27:18Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LiveSquawk</td>\n",
       "      <td>130351</td>\n",
       "      <td>435511902</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nancy Pelosi Buys Tesla Calls, Stands To Benef...</td>\n",
       "      <td>2021-01-26T19:33:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>7108</td>\n",
       "      <td>277882388</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Big Dividend Stocks Yielding 7% — or More; E...</td>\n",
       "      <td>2020-09-28T13:45:47Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TipRanks</td>\n",
       "      <td>217593</td>\n",
       "      <td>246681035</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Value Investing Is Alive And Well: 5 Picks. $S...</td>\n",
       "      <td>2020-08-11T21:23:36Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZacksResearch</td>\n",
       "      <td>82492</td>\n",
       "      <td>235582933</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AB stalking as a potential swing long above 2...</td>\n",
       "      <td>2020-06-18T16:30:28Z</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>ACInvestorBlog</td>\n",
       "      <td>2503</td>\n",
       "      <td>221060450</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            created_at  \\\n",
       "0  $AB | AllianceBernstein Q4 21 Earnings: \\nAdj ...  2022-02-11T11:27:18Z   \n",
       "1  Nancy Pelosi Buys Tesla Calls, Stands To Benef...  2021-01-26T19:33:19Z   \n",
       "2  3 Big Dividend Stocks Yielding 7% — or More; E...  2020-09-28T13:45:47Z   \n",
       "3  Value Investing Is Alive And Well: 5 Picks. $S...  2020-08-11T21:23:36Z   \n",
       "4  $AB stalking as a potential swing long above 2...  2020-06-18T16:30:28Z   \n",
       "\n",
       "  bear_bull_tag       user_name  user_id  message_id ticker  \n",
       "0           NaN      LiveSquawk   130351   435511902     AB  \n",
       "1           NaN        Benzinga     7108   277882388     AB  \n",
       "2           NaN        TipRanks   217593   246681035     AB  \n",
       "3           NaN   ZacksResearch    82492   235582933     AB  \n",
       "4       Bullish  ACInvestorBlog     2503   221060450     AB  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30320fe8-26e6-4e57-a698-0e09cf4e17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    \"\"\"\n",
    "    Clean text in the dataset.\n",
    "    \n",
    "    :param txt: txt string that is present in the input file.\n",
    "    :type  txt: str\n",
    "    :return: string that has been cleaned using Wordnet Lemmatizer, etc. \n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    \n",
    "    txt = txt.lower()  # convert to lowercase\n",
    "    txt = re.sub(r'^https?:\\/\\/.*[\\s]*', '', txt)  # remove links\n",
    "    words = txt.split(\" \")\n",
    "    # remove tickers\n",
    "    words_without_tickers = []\n",
    "    for w in words:\n",
    "        if w.startswith(\"$\") and len(w) > 1:\n",
    "            continue\n",
    "        words_without_tickers += [w]\n",
    "    non_ticker_text = \" \".join(words_without_tickers)\n",
    "    words = nltk.tokenize.word_tokenize(non_ticker_text)  # tokenize\n",
    "    words = [word if word.isalpha() else '' for word in words]  # only retains words, not numbers, etc.\n",
    "    lemmatizer = nltk.wordnet.WordNetLemmatizer()\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')).union(set([\"hey\", \"http\", \"https\", \n",
    "                                                                        \"u\", \"im\", \"amp\"]))\n",
    "    final_tokens = []\n",
    "    for w in words:\n",
    "        w = \"\".join([\"\" if c in string.punctuation else c for c in w])  # remove punctutation\n",
    "        if w != \"\" and w not in stop_words:  # process only non stopwords\n",
    "            final_tokens.append(lemmatizer.lemmatize(w))  # using WordNet for lemmatizing\n",
    "    cleaned_txt = \" \".join(final_tokens)\n",
    "    return cleaned_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762187c7-eacc-404f-8776-8d5a3d370288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing bots\n",
    "df = df[~df.user_name.isin([\"OpenOutcrier\", \"briefingcom\", \"Estimize\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ea5611-ecee-4953-8336-82401cdc1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda r: clean_text(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36907b0-7fdb-4aff-86eb-0108ca6d99ca",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dcf10e-b98a-45f4-ad5a-a49942834ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=set(nltk.corpus.stopwords.words('english')), \n",
    "                             max_features=1000)\n",
    "X = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0f3411-7679-4b3e-9479-7b128ccf9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d8e75-5bbc-4c3b-8672-193eb0019572",
   "metadata": {},
   "source": [
    "### MiniSom\n",
    "https://github.com/JustGlowing/minisom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bdce590-7bc8-4f96-82ab-14861c2f69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = X.todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02d0757-2aaa-4861-b58d-d724e2675c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3  # lattice dimension\n",
    "som = MiniSom(M, M, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901b4341-3844-441e-9f8b-b5fe843b6db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 50000 / 50000 ] 100% - 0:00:00 left \n",
      " quantization error: 0.9920790629896886\n"
     ]
    }
   ],
   "source": [
    "som.pca_weights_init(D)\n",
    "som.train(D, 50000, random_order=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a861e6-8c20-4503-becf-4dd48f8bfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keywords = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ee6b3f-91b3-405d-a080-d4f2d6a038f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = som.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395a0593-87fc-46ae-9a43-29adcb278240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 : trading longs hard going parabolic position profit congrats ran alerted\n",
      "Topic 2 : study offering stock positive daily fda pulse result biotech surge\n",
      "Topic 3 : watch longs close level holding overnight congrats parabolic squeeze go\n",
      "Topic 4 : congrats mover market pre pm pt today part top gainer\n",
      "Topic 5 : data continuation turn watchlist breaking hard move running partnership starting\n",
      "Topic 6 : monster looking hot week several setup gapping set ups energy\n",
      "Topic 7 : parabolic pre higher lower hour part yesterday biggest top mover\n",
      "Topic 8 : possible trading new stock pro benzinga upside international watch today\n",
      "Topic 9 : rated rate maintained security capital success stock analyst reiterated buy\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for i in range(M):\n",
    "    for j in range(M):\n",
    "        keywords_idx = np.argsort(weights[i,j,:])[-top_keywords:]\n",
    "        keywords = ' '.join([feature_names[k] for k in keywords_idx])\n",
    "        print('Topic', cnt, ':', keywords)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec1639-ddf8-4eb4-ab7c-5a1513d40d6c",
   "metadata": {},
   "source": [
    "### 2. sklearn-som\n",
    "https://github.com/rileypsmith/sklearn-som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab3e785-2bed-4b03-a78f-d4bc0a703f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM(M, M, X.shape[1])\n",
    "som.fit(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4658fffd-3bfa-4a6c-a7c8-8196d018a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = som.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8940267-274e-42f4-8698-354ac485ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 : eps million week name sale general morning mover tariff ipo\n",
      "Topic 2 : stock today read gap good trade etf hour morning mover\n",
      "Topic 3 : china increase big high mover top near quot today stock\n",
      "Topic 4 : long week etf new tell time next morning earnings name\n",
      "Topic 5 : sector real broke move top morning market vehicle stock etf\n",
      "Topic 6 : analyst new market today dividend etf gainer buy top stock\n",
      "Topic 7 : trade report amd morning name close say stock week earnings\n",
      "Topic 8 : amid vaccine testing analyst etf say buy coronavirus stock earnings\n",
      "Topic 9 : success notable say dip top upgrade maintained analyst stock buy\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for i in range(M * M):\n",
    "    keywords_idx = np.argsort(weights[i])[-top_keywords:]\n",
    "    keywords = ' '.join([feature_names[k] for k in keywords_idx])\n",
    "    print('Topic', cnt, ':', keywords)\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
